{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8: 딥러닝\n",
    "딥러닝은 층을 깊게 한 심층 신경망  \n",
    "  \n",
    "심층 신경망은 지금까지 설명한 신경망을 바탕으로 뒷단에 layer를 추가하기만 하면 만들 수 있지만, 커다란 문제가 몇 가지 있음  \n",
    "  \n",
    "Chapter 8에서는 딥러닝의 특징과 과제, 가능성을 살펴봄  \n",
    "  \n",
    "> ### **8.1** 더 깊게\n",
    "> \n",
    "> 신경망에 관해 그동안 많은 것을 배움  \n",
    "> \n",
    "> 신경망을 구성하는 다양한 계층과 학습에 효과적인 기술, 영상 분야에 특히 유효한 CNN과 매개변수 최적화 기법 등  \n",
    "> \n",
    "> 이 모두가 딥러닝에서 중요한 기술  \n",
    "> \n",
    "> 그동안 배운 기술을 집약하고 심층 신경망을 만들어 MNIST 데이터셋의 손글씨 숫자 인식에 도전  \n",
    ">>\n",
    ">> ##### 더 깊은 신경망으로  \n",
    ">> 그림 8-1과 같이 구성된 CNN을 만들고자 함(VGG 신경망을 참고한 신경망)  \n",
    ">> \n",
    ">> ![pic/deep_network_structure](pic/deep_network_structure.png)  \n",
    ">> \n",
    ">> 지금까지 구현한 신경망보다 층이 깊음  \n",
    ">> \n",
    ">> 여기에서 사용하는 Conv layer는 모두 $3 \\times 3$ 크기의 작은 필터로, layer가 깊어지며 채널 수가 더 늘어나는 것이 특징 (Conv layer의 채널 수는 앞 계층에서부터 순서대로 16, 16, 32, 32, 64, 64로 늘어감)  \n",
    ">> \n",
    ">> 또 그림과 같이 Pooling layer를 추가하여 중간 데이터의 공간 크기를 점차 줄여감  \n",
    ">> \n",
    ">> 마지막 단의 fully-connected layer에서는 dropout layer를 사용함  \n",
    ">> \n",
    ">> 가중치 조깃값으로 He 초깃값을 사용, 가중치 매개변수 갱신에는 Adam 이용  \n",
    ">> \n",
    ">> 그림의 신경망의 특징  \n",
    ">> * $3 \\times 3$의 작은 필터를 사용  \n",
    ">> * activation function은 ReLu  \n",
    ">> * fully-connected layer 뒤에 dropout layer사용  \n",
    ">> * Opimizer는 Adam  \n",
    ">> * 가중치 초깃값은 'He'초깃값 \n",
    ">> \n",
    ">> 이상의 특징에서 보듯 이 신경망에는 그동안 배운 신경망 기술을 잔뜩 녹여놓음  \n",
    ">> \n",
    ">> 결과는 정화도 99.38%  \n",
    ">> \n",
    ">> 이 신경망을 구현한 소스 코드는 ch08/deep_convnet.py에, 훈련용 코드는 ch08/train_deepnet.py에 준비되어 있음  \n",
    ">> \n",
    ">> 이 코드를 사용하여 학습을 직접 시켜봐도 좋지만, 심층 신경망을 학습시키는 데는 시간이 오래 걸림  \n",
    ">> \n",
    ">> 이 책에서는 학습된 가중치 매개변수를 ch08/deep_conv_net_params.pkl 파일에 준비해 놓음  \n",
    ">> 이전의 deep_convnet.py는 학습된 매개변수를 읽어 들일 수 있으니 적절히 이용할 것  \n",
    "\n",
    ">> ##### 정확도를 더 높이려면  \n",
    ">> \n",
    ">> \"What is the class of this image?\" 웹 사이트는 다양한 데이터셋을 대상으로 그동안 논문 등에서 발표한 기법들의 정확도 순위를 정리해 두었음  \n",
    ">> \n",
    ">> 위 웹 사이트의 상위 기법들을 참고하면 정확도를 더 높일 수 있는 기술이나 힌트를 발견할 수 있음  \n",
    ">> \n",
    ">> 예를 들어 ensemble learning, learning rate decay, data argumentation 등이 정확도 향상에 공헌하고 있음  \n",
    ">> \n",
    ">> 특히 data argumentation은 손쉬운 방법이면서도 정확도 개선에 아주 효과적임  \n",
    ">> \n",
    ">> data argumentation은 입력 이미지(훈련 이미지)를 알고리즘을 동원해 '인위적'으로 확장함  \n",
    ">> \n",
    ">> 그림 8-4와 같이 입력 이미지를 회전하거나 세로로 이동하는 등 미세한 변화를 주어 이미지의 개수를 늘리는 것  \n",
    ">> \n",
    ">> ![pic/data_argumentation](pic/data_argumentation.png)  \n",
    ">> \n",
    ">> 이는 데이터가 몇 없을 때 특히 효과적인 수단  \n",
    ">> \n",
    ">> data argumentation은 위 그림과 같은 변형 외에도 다양한 방법으로 이미지를 확장할 수 있음  \n",
    ">> \n",
    ">> 예를 들어 이미지 일부를 잘라내는 crop이나 좌우를 뒤집는 flip 등이 있음  \n",
    ">> \n",
    ">> 일반적인 이미지에는 밝기 등의 외형 변화나 확대 &middot; 축소 등의 스케일 변화도 효과적임  \n",
    "\n",
    ">> ##### 깊게 하는 이유  \n",
    ">> layer를 깊게하는 것이 왜 중요한가에 대한 이론적인 근거는 아직 많이 부족한 것이 사실  \n",
    ">> \n",
    ">> 그래도 지금까지의 연구와 실험 결과를 바탕으로 설명할 수 있는 것은 몇 가지 있음  \n",
    ">> \n",
    ">> 층을 깊게하는 것의 중요성은 ILSVRC로 대표되는 대규모 이미지 인식 대회의 결과에서 파악할 수 있음  \n",
    ">> \n",
    ">> 이 대회에서 상위를 차지한 기법 대부분은 딥러닝 기반이며, 그 경향은 신경망을 더 깊게 만드는 방향으로 가고 있음  \n",
    ">> \n",
    ">> layer의 깊이에 비례해 정확도가 좋아지는 것  \n",
    ">> \n",
    ">> layer를 깊게 할 때의 이점  \n",
    ">> * 신경망의 매개변수 수가 줄어듦  \n",
    ">> &nbsp; &nbsp; &rarr; layer를 깊게 한 신경망은 깊지 않은 경우보다 적은 매개변수로 같거나 그 이상의 수준의 표현력을 달성할 수 있음  \n",
    ">>> Conv 연산에서의 필터 크기에 주목해 생각해보면 쉽게 이해할 수 있음  \n",
    ">>>  \n",
    ">>> ![pic/advantage_of_deep_network.png](pic/advantage_of_deep_network.png)  \n",
    ">>> 그림 8-5는 $5 \\times 5$필터로 구성된 Conv layer  \n",
    ">>> \n",
    ">>> 여기에서 주목할 점은 출력 데이터의 각 노드가 입력 데이터의 어느 영역으로부터 계산되었느냐는 것  \n",
    ">>> \n",
    ">>> 당연하지만 위 그림의 예에서는 각각의 출력 노드는 입력 데이터의 $5 \\times 5$크기 영역에서 계산됨  \n",
    ">>> \n",
    ">>> 이러서 그림 8-6처럼 $3 \\times 3$의 Conv 연산을 2회 반복하는 경우를 생각해보면, 이 경우 출력 노드 하나는 중간 데이터의 $3 \\times 3$영역에서 계산됨  \n",
    ">>> \n",
    ">>> 그럼 중간 데이터의 $3 \\times 3$영역은 그 전 입력 데이터의 어느 영역에서 계산될까?  \n",
    ">>> \n",
    ">>> ![pic/conv_layer_](pic/conv_layer_.png)  \n",
    ">>> \n",
    ">>> 그림 8-6을 잘 보면 $5 \\times 5$ 크기의 영역에서 계산되어 나오는 것을 알 수 있음  \n",
    ">>> \n",
    ">>> 즉 위 그림의 출력 데이터는 입력 데이터의 $5 \\times 5$ 크기의 영역을 '보고' 계산하게 됨  \n",
    ">>> \n",
    ">>> $5 \\times 5$의 Conv 연산 1회는 $3 \\times 3$의 Conv 연산을 2회 수행하여 대체할 수 있음  \n",
    ">>> \n",
    ">>> 게다가 전자의 매개변수 수가 25개($5 \\times 5$)인 반면, 후자는 총 18개 ($2 \\times 3 \\times 3$)이며, 매개변수 수는 layer를 반복할수록 적어짐  \n",
    ">>> \n",
    ">>> 그리고 그 개수의 차이는 layer가 깊어질수록 커짐  \n",
    ">>> \n",
    ">>> 예를 들어 $3 \\times 3$의 Conv 연산을 3회 반복하면 매개변수는 모두 27개가 되지만, 같은 크기의 영역을 1회의 Conv 연상으로 '보기' 위해서는 $7 \\times 7$크기의 필터, 즉 매개변수 49개가 필요함  \n",
    ">>> \n",
    ">>> 작은 필터를 겹쳐 신경망을 깊게할 때의 장점은 매개변수 수를 줄여 넓은 수용 영역(뉴런에 변화를 일으키는 국소적인 공간 영역)을 소화할 수 있다는 데 있음  \n",
    ">>> \n",
    ">>> 게다가 층을 거듭하면서 ReLU 등의 activation function을 Conv layer 사이에 끼움으로써 신경망의 표현력이 개선됨  \n",
    ">>> \n",
    ">>> 이는 activation function이 신경망에 'non-linear'힘을 가하고, non-linear function이 겹치면서 더 복잡한 것도 표현할 수 있게 되기 때문  \n",
    ">>> \n",
    ">> * 학습의 효율성  \n",
    ">> &nbsp; &nbsp; &rarr; layer를 깊게 함으로써 학습 데이터의 양을 줄여 학습을 고속으로 수행할 수 있다는 뜻  \n",
    ">>> 이를 이해하려면 7.6 CNN 시각화하기에서의 설명을 생각하면 좋을 것  \n",
    ">>> \n",
    ">>> 7.6에서 CNN의 Conv layer가 정보를 계층적으로 추출하고 있음을 설명함  \n",
    ">>> \n",
    ">>> 앞단의 Conv layer에서는 edge 등의 단순한 패턴에 뉴런이 반응하고 layer가 깊어지면서 texture와 사물의 일부와 같이 점차 더 복잡한 것에 반응한다고 설명함  \n",
    ">>> \n",
    ">>> 이러한 네트워크 계층 구조를 기억해두고, '개'를 인식하는 문제를 생각해 보자  \n",
    ">>> \n",
    ">>> 이 문제를 얕은 신경망에서 해결하려면 Conv layer는 개의 특징 대부분을 한 번에 '이해'해야 함  \n",
    ">>> \n",
    ">>> 견종도 다양하고 어느 각도에서 찍은 사진이냐에 따라 완전히 다르게 보일 수 있음, 그래서 개의 특징을 이해하려면 변화가 풍부하고 많은 학습 데이터가 필요하고, 결과적으로 학습 시간이 오래걸림  \n",
    ">>> \n",
    ">>> 그러나 신경망을 깊게하면 학습해야 할 문제를 계층적으로 분해할 수 있음  \n",
    ">>> \n",
    ">>> 각 layer가 학습해야 할 문제를 더 단순한 문제로 대체할 수 있는 것  \n",
    ">>> \n",
    ">>> 예를 들어 처음 layer는 edge 학습에 전념하여 적은 학습 데이터로 효율적으로 학습할 수 있음  \n",
    ">>> \n",
    ">>> 개가 등장하는 이미지보다 edge를 포함한 이미지는 많고, edge의 패턴은 개라는 패턴보다 구조가 훨씬 간단하기 때문  \n",
    ">>>\n",
    ">>> layer를 깊게 하면 정보를 계층적으로 전달할 수 있다는 점도 중요  \n",
    ">>> \n",
    ">>> 예를 들어 edge를 추출한 layer의 다음 layer는 edge 정보를 쓸 수 있고, 더 고도의 패턴을 효과적으로 학습하리라 기대할 수 있음  \n",
    ">>> &nbsp; &nbsp; &rarr; 즉, layer를 깊이함으로써 각 층이 학습해야 할 문제를 '풀기 쉬운 단순한 문제'로 분해할 수 있어 효율적으로 학습하리라 기대할 수 있음  \n",
    ">>> \n",
    ">> 이상이 layer를 깊게 하는 것이 왜 중요한가에 대한 보충 설명  \n",
    ">> \n",
    ">> 최근 일어나고 있는 layer의 심화는 layer가 깊어도 제대로 학습할 수 있도록 해주는 새로운 기술과 환경 (빅데이터와 컴퓨터 연산 능력 등)이 뒷받침되어 나타난 현상임  \n",
    "\n",
    "> ### **8.2** 딥러닝의 초기 역사  \n",
    "> 딥러닝이 지금처럼 큰 주목을 받게된 계기는 이미지 인식 기술을 겨루는 장인 ILSVRC(ImageNet Large Scale Visual Recognition Challenge)의 2012년 대회  \n",
    "> \n",
    "> 이 대회에서 딥러닝에 기초한 기법, 일명 AlexNet이 압도적인 성적으로 우승하며 그동안의 이미지 인식에 대한 접근법을 뿌리부터 뒤흔듦  \n",
    "> \n",
    "> 그 후로는 대회의 주역은 항상 딥러닝이었음  \n",
    "> \n",
    "> ILSVRC 대회를 축으로 딥러닝 트렌드를 살펴봄  \n",
    ">> \n",
    ">> ##### ImageNet  \n",
    ">> ImageNet은 100만장이 넘는 이미지를 담고 있는 데이터셋  \n",
    ">> \n",
    ">> 그림 8-7과 같이 다양한 종류의 이미지를 포함하여 각 이미지에는 label(class name)이 붙어 있음  \n",
    ">> \n",
    ">> 매년 열리는 ILSVRC는 이 거대한 데이터셋을 사용하여 자웅을 겨루는 이미지 인식 기술 대회  \n",
    ">>  \n",
    ">> ![pic/imagenet.png](pic/imagenet.png)  \n",
    ">> \n",
    ">> ILSVRC 대회에는 시험 항목이 몇 가지 있는데, 그중 하나가 classification  \n",
    ">> \n",
    ">> classification 부문에서는 1,000개의 class를 제대로 분류하는지를 겨룸  \n",
    ">>  \n",
    ">> 최근 몇 년 빼어난 성적을 거두고 있는 딥러닝 중에서도 VGG, GoogLeNet, ResNet은 특히 유명하며, 다양한 딥러닝 분야에서 활용됨  \n",
    "\n",
    ">> ##### VGG  \n",
    ">> VGG는 Conv layer와 Pooling layer로 구성되는 '기본적'인 CNN  \n",
    ">> \n",
    ">> 다만 그림 8-9와 같이 비중있는 layer(Conv layer, fully-connected layer)를 모두 16층(혹은 19층)으로 심화한 게 특징 (layer의 깊이에 따라 'VGG16'과 'VGG19'로 구분하기도 함)  \n",
    ">> \n",
    ">> ![pic/vgg](pic/vgg.png)  \n",
    ">> \n",
    ">> VGG에서 주목할 점은 $3 \\times 3$의 작은 필터를 사용한 Conv layer를 연속으로 거친다는 것  \n",
    ">> \n",
    ">> 그림에서 보듯 Conv layer를 2~4회 연속으로 Pooling layer를 두어 크기를 절반으로 줄이는 처리를 반복  \n",
    ">> \n",
    ">> 그리고 마지막에는 fully-connected layer를 통과시켜 결과를 출력  \n",
    "\n",
    ">> ##### GoogLeNet  \n",
    ">> GoogLeNet의 구성은 그림 8-10과 같음  \n",
    ">> \n",
    ">> 그림의 사각형이 Conv layer와 Pooling layer등의 layer를 나타냄  \n",
    ">> \n",
    ">> ![pic/googlenet](pic/googlenet.png)  \n",
    ">> \n",
    ">> 그림을 보면 구성이 매우 복잡해 보이는데, 기본적으로는 지금까지 보아온 CNN과 다르지 않음  \n",
    ">> \n",
    ">> 단, GoogLeNet은 세로 방향 깊이뿐 아니라 기로 방향도 깊다는 점이 특징  \n",
    ">> \n",
    ">> GoogLeNet에는 가로 방향에 '폭'이 있음  \n",
    ">> &nbsp; &nbsp; &rarr; 이를 inception 구조라 하며, 그 기반 구조는 그림 8-11과 같음  \n",
    ">> \n",
    ">> ![pic/inception](pic/inception.png)  \n",
    ">> \n",
    ">> inception 구조는 위 그림과 같이 크기가 다른 필터(와 pooling)를 여러 개 적용하여 그 결과를 결함  \n",
    ">> \n",
    ">> 이 inception 구조를 하나의 빌딩 블록(구성요소)으로 사용하는 것이 GoogLeNet의 특징  \n",
    ">> \n",
    ">> 또 GoogLeNet에서는 $1 \\times 1$ 크기의 필터를 사용한 Conv layer를 많은 곳에서 사용함  \n",
    ">> \n",
    ">> 이 $1 \\times 1$의 Conv 연산은 채널 쪽으로 크기를 줄이는 것으로, 매개변수 제거와 고속 처리에 기여함  \n",
    "\n",
    ">> ##### ResNet  \n",
    ">> ResNet은 Microsoft 팀이 개발한 네트워크  \n",
    ">> \n",
    ">> 그 특징은 지금까지보다 layer를 더 깊게할 수 있는 특별한 '장치'에 있음  \n",
    ">> \n",
    ">> 지금까지 layer를 깊게 하는 것이 성능 향상에 중요하다는 것은 알고 있었음  \n",
    ">> \n",
    ">> 그러나 딥러닝의 학습에서는 layer가 지나치게 깊으면 학습이 잘 되지 않고, 오히려 성능이 떨어지는 경우도 많음  \n",
    ">> \n",
    ">> ResNet에서는 그런 문제를 해결하기 위해 skip connection을 도입함  \n",
    ">> \n",
    ">> 이 구조가 layer의 깊이에 비례해 성능을 향상시킬 수 있게 한 핵심 (물론 layer를 깊게 하는 데는 여전히 한계가 있음)  \n",
    ">> \n",
    ">> skip connection이란 그림 8-12와 같이 입력 데이터를 Conv layer를 건너뛰어 출력에 바로 더하는 구조를 말함  \n",
    ">> \n",
    ">> ![pic/skip_connection](pic/skip_connection.png)  \n",
    ">> \n",
    ">> 그림 8-12에서는 입력 $x$를 연속한 두 Conv layer를 건너뛰어 출력에 바로 연결함  \n",
    ">> \n",
    ">> 이 단축 경로가 없었다면 두 Conv layer의 출력이 $F(x)$가 되지만, skip connection으로 인해 $F(x) + x$가 되는 게 핵심  \n",
    ">> \n",
    ">> skip connection은 layer가 깊어져도 학습을 효율적으로 할 수 있도록 해주는데, 이는 역전파 때 skip connection이 신호 감쇠를 막아주기 때문  \n",
    ">> \n",
    ">> skip connection은 입력 데이터를 '그대로' 흘리는 것으로, 역전파 때도 상류의 기울기를 그대로 하류로 보냄  \n",
    ">> \n",
    ">> 여기에서 핵심은 상류의 기울기에 아무런 수정도 가하지 않고 '그대로' 흘린다는 것  \n",
    ">> \n",
    ">> 그래서 skip connection으로 기울기가 작아지거나 지나치게 커질 걱정 없이 앞 layer에 '의미 있는 기울기'가 전해지리라 기대할 수 있음  \n",
    ">> \n",
    ">> layer를 깊게 할수록 기울기가 작아지는 소실 문제를 이 skip connection이 줄여줌  \n",
    ">> \n",
    ">> ResNet은 앞서 설명한 VGG 신경망을 기반으로 skip connection을 도입하여 layer를 깊게 함, 그 결과는 그림 8-13처럼 됨  \n",
    ">> \n",
    ">> ![pic/resnet_structure.png](pic/resnet_structure.png)  \n",
    ">> \n",
    ">> 그림 8-13과 같이 ResNet은 Conv layer를 2개 layer마다 건너뛰면서 layer를 깊게 함  \n",
    ">> \n",
    ">> 실험 결과 150층 이상으로 해도 정확도가 오르는 모습을 확인할 수 있음  \n",
    ">> \n",
    ">> ImageNet이 제공하는 거대한 데이터셋으로 학습한 가중치 값들은 실제 제품에 활용해도 효과적이고, 많이들 그렇게 이용하고 있음  \n",
    ">> 이를 transfer learning이라고 해서, 학습된 가중치 혹은 그 일부를 다른 신경망에 복사한 다음, 그 상태로 재학습을 수행함  \n",
    ">> \n",
    ">> 예를 들어 VGG와 구성이 같은 신경망을 준비하고, 미리 학습된 가중치를 초깃값으로 설정한 후, 새로운 데이터셋을 대상으로 fine tuning(재학습)을 수행함  \n",
    ">> \n",
    ">> transfer learning은 보유한 데이터셋이 적을 때 특히 유용함"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
