{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3: Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### **3.2** 활성화 함수\n",
    ">> ##### step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step function\n",
    "def step_function(x):\n",
    "    if x>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "step_function(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  1.  2.]\n",
      "[False  True  True]\n",
      "[0 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tz/r67lvvbd1snd1tps26_tv6hh0000gn/T/ipykernel_8971/103660353.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  print(y.astype(np.int))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([-1.0, 1.0, 2.0])\n",
    "print(x)\n",
    "\n",
    "y = x>0\n",
    "print(y)\n",
    "\n",
    "print(y.astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tz/r67lvvbd1snd1tps26_tv6hh0000gn/T/ipykernel_8971/3421200715.py:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return y.astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "# step function, numpy array argument\n",
    "def step_function(x):\n",
    "    y = x>0\n",
    "    return y.astype(np.int)\n",
    "\n",
    "print(step_function(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tz/r67lvvbd1snd1tps26_tv6hh0000gn/T/ipykernel_8971/1884667470.py:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return np.array(x>0, dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def step_function(x):\n",
    "    return np.array(x>0, dtype=np.int)\n",
    "\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = step_function(x)\n",
    "plt.plot(x, y)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ##### sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26894142, 0.73105858, 0.88079708])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# sigmoid function, numpy broadcast\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "x = np.array([-1.0, 1.0, 2.0])\n",
    "sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(-5.0, 5.0, 0.1)\n",
    "y = sigmoid(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ##### ReLU function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ReLU function\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "x = 0.12\n",
    "relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### **3.3** 다차원 배열의 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "1\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1차원 배열\n",
    "A = np.array([1,2,3,4])\n",
    "\n",
    "print(A)\n",
    "print(np.ndim(A))   # 배열의 차원수\n",
    "print(A.shape)    # 배열의 모양, 튜플 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "2\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "# 2차원 배열, Matrix\n",
    "B = np.array([[1,2], [3,4], [5,6]])\n",
    "\n",
    "print(B)\n",
    "print(np.ndim(B))\n",
    "print(B.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Matirx](pic/matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ##### 행렬의 곱\n",
    ">> ![Matirx_product](pic/matrix_product.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "(2, 2)\n",
      "[[19 22]\n",
      " [43 50]]\n",
      "[[23 34]\n",
      " [31 46]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,2], [3,4]])\n",
    "B = np.array([[5,6], [7,8]])\n",
    "\n",
    "print(A.shape)\n",
    "print(B.shape)\n",
    "# np.dot(A,B) != np.dot(B,A)\n",
    "print(np.dot(A,B))\n",
    "print(np.dot(B,A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Matirx_dot product](pic/matirx_dot_product.png)\n",
    "![Matirx_dot product](pic/matrix_vector_product.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(2,)\n",
      "[23 53 83]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,2], [3,4], [5,6]])\n",
    "B = np.array([7,8])\n",
    "\n",
    "print(A.shape)\n",
    "print(B.shape)\n",
    "print(np.dot(A,B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ##### 신경망에서의 행렬 곱\n",
    ">> ![neural_network](matrix_product_on_neural_network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "(2, 3)\n",
      "[ 5 11 17]\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1,2])\n",
    "W = np.array([[1,3,5], [2,4,6]])\n",
    "Y = np.dot(X,W)\n",
    "\n",
    "print(X.shape)\n",
    "print(W.shape)\n",
    "\n",
    "print(Y)\n",
    "print(Y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### **3.4** 3층 신경망 구현하기\n",
    ">> ![3layer_neural network](3layer_neural_network.png)\n",
    ">> ![3layer_neural network](표기법.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ##### 각 층의 신호 전달 구현하기\n",
    ">>![delivery](delivery.png)\n",
    ">>![calculation](calculation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2,)\n",
      "(3,)\n",
      "[0.3 0.7 1.1]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1.0, 0.5])\n",
    "W1 = np.array([[0.1,0.3,0.5], [0.2,0.4,0.6]])\n",
    "B1 = np.array([0.1, 0.2, 0.3])\n",
    "\n",
    "print(W1.shape)\n",
    "print(X.shape)\n",
    "print(B1.shape)\n",
    "\n",
    "A1 = np.dot(X, W1)+B1\n",
    "print(A1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![activate_function](activate_function.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3 0.7 1.1]\n",
      "[0.57444252 0.66818777 0.75026011]\n"
     ]
    }
   ],
   "source": [
    "# 활성화 함수 = sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "Z1 = sigmoid(A1)\n",
    "\n",
    "print(A1)\n",
    "print(Z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![delivery_1-2](delivery_1-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3, 2)\n",
      "(2,)\n",
      "[0.51615984 1.21402696]\n",
      "[0.62624937 0.7710107 ]\n"
     ]
    }
   ],
   "source": [
    "W2 = np.array([[0.1,0.4], [0.2,0.5], [0.3,0.6]])\n",
    "B2 = np.array([0.1, 0.2])\n",
    "\n",
    "print(Z1.shape)\n",
    "print(W2.shape)\n",
    "print(B2.shape)\n",
    "\n",
    "A2 = np.dot(Z1, W2)+B2\n",
    "Z2 = sigmoid(A2)\n",
    "print(A2)\n",
    "print(Z2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![delivery_2-out](delivery_2-out.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31682708 0.69627909]\n",
      "[0.31682708 0.69627909]\n"
     ]
    }
   ],
   "source": [
    "def identity_function(x):\n",
    "    return x\n",
    "\n",
    "W3 = np.array([[0.1,0.3], [0.2,0.4]])\n",
    "B3 = np.array([0.1, 0.2])\n",
    "\n",
    "A3 = np.dot(Z2, W3)+B3\n",
    "Y = identity_function(A3)\n",
    "print(A3)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31234736 0.6863161 ]\n"
     ]
    }
   ],
   "source": [
    "# 3층 신경망\n",
    "def init_network():\n",
    "    network = {}\n",
    "    network['W1'] = np.array([[0.1,0.3,0.5], [0.2,0.4,0.6]])\n",
    "    network['b1'] = np.array([0.1, 0.2, 0.3])\n",
    "    network['W2'] = np.array([[0.1,0.4], [0.2,0.5], [0.3,0.6]])\n",
    "    network['b2'] = np.array([0.1, 0.2])\n",
    "    network['W3'] = np.array([[0.1,0.3], [0.2,0.4]])\n",
    "    network['b3'] = np.array([0.1, 0.2])\n",
    "\n",
    "    return network\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def identity_function(x):\n",
    "    return x\n",
    "\n",
    "def forward(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "\n",
    "    a1 = np.dot(x, W1)+b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2)+b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3)+b3\n",
    "    y = identity_function(a3)\n",
    "\n",
    "    return y\n",
    "\n",
    "network = init_network()\n",
    "x = np.array([0.1, 0.5])\n",
    "y = forward(network, x)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### **3.5** 출력층 설계하기\n",
    ">> ##### 항등 함수와 소프트맥스 함수 구현하기\n",
    ">> ![identity_function](identity_function.png)\n",
    ">> ![softmax_function](softmax_function.png)\n",
    ">> ![softmax_pic](softmax_pic.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.34985881 18.17414537 54.59815003]\n",
      "74.1221542101633\n",
      "[0.01821127 0.24519181 0.73659691]\n"
     ]
    }
   ],
   "source": [
    "# softmax function, stage by stage\n",
    "a = np.array([0.3, 2.9, 4.0])\n",
    "exp_a = np.exp(a)\n",
    "print(exp_a)\n",
    "\n",
    "sum_exp_a = np.sum(exp_a)\n",
    "print(sum_exp_a)\n",
    "\n",
    "y = exp_a/sum_exp_a\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax function\n",
    "def softmax(a):\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a/sum_exp_a\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan]\n",
      "[  0 -10 -20]\n",
      "[9.99954600e-01 4.53978686e-05 2.06106005e-09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tz/r67lvvbd1snd1tps26_tv6hh0000gn/T/ipykernel_8971/2273214736.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  print(np.exp(a)/np.sum(np.exp(a)))\n",
      "/var/folders/tz/r67lvvbd1snd1tps26_tv6hh0000gn/T/ipykernel_8971/2273214736.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  print(np.exp(a)/np.sum(np.exp(a)))\n"
     ]
    }
   ],
   "source": [
    "# softmax function, overflow\n",
    "a = np.array([1010, 1000, 990])\n",
    "print(np.exp(a)/np.sum(np.exp(a)))  # overflow\n",
    "\n",
    "c = np.max(a)\n",
    "print(a - c)    # to prevnet overflow, 가장 큰 값 빼주기\n",
    "\n",
    "print(np.exp(a-c)/np.sum(np.exp(a-c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax function, complement overflow\n",
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a/sum_exp_a\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ##### 소프트맥스 함수의 특징\n",
    ">> * softmax function의 출력은 0에서 1사이의 실수\n",
    ">> * softmax function의 출력의 총합은 1  \n",
    ">> 따라서 softmax function의 출력을 '확률'로 해석할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01821127 0.24519181 0.73659691]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "a = np.array([0.3, 2.9, 4.0])\n",
    "y = softmax(a)\n",
    "print(y)    # outputs of softmax function are real number between 0 and 1\n",
    "print(np.sum(y))    # sum of outputs is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> * softmax function을 적용해도 각 원소의 대소 관계는 변하지 않음  \n",
    ">> (y = exp(x)가 단조 증가 함수이기 때문)  \n",
    ">> 따라서 신경망 분류에서 출력층의 softmax function은 생략해도 무관  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ##### 출력층의 뉴런 수 정하기\n",
    ">> * 문제에 맞게 적절히 정해야\n",
    ">> * 분류 문제에서는 분류하고 싶은 클래스 수로 설정하는 것이 일반적\n",
    "![out_layer](out_layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### **3.6** 손글씨 숫자 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Creating pickle file ...\n",
      "Done!\n",
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# mnist 데이터 불러오기\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)\n",
    "print(x_test.shape)\n",
    "print(t_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "(784,)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "# mnist 이미지\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def img_show(img):\n",
    "    pil_img = Image.fromarray(np.uint8(img))\n",
    "    pil_img.show()\n",
    "\n",
    "img = x_train[0]\n",
    "label = t_train[0]\n",
    "print(label)\n",
    "\n",
    "print(img.shape)\n",
    "img = img.reshape(28,28)\n",
    "print(img.shape)\n",
    "\n",
    "img_show(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ##### 신경망의 추론 처리\n",
    ">> * 정규화: 데이터를 특정 범위로 변환하는 처리  \n",
    ">> (ex. 0~255 -> 0.0~1.0)\n",
    ">> * 전처리: 신경망의 입력 데이터에 특정 변환을 가하는 것  \n",
    ">> (ex. 정규화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 구현\n",
    "import sys, os\n",
    "import pickle\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
    "    return x_test, t_test\n",
    "\n",
    "def init_network():\n",
    "    with open(\"ch03/sample_weight.pkl\", 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "    \n",
    "    return network\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a/sum_exp_a\n",
    "    \n",
    "    return y\n",
    "\n",
    "def predict(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "\n",
    "    a1 = np.dot(x, W1)+b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2)+b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3)+b3\n",
    "    y = softmax(a3)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9352\n"
     ]
    }
   ],
   "source": [
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(len(x)):\n",
    "    y = predict(network, x[i])\n",
    "    p = np.argmax(y)    # 확률이 가장 높은 원소의 인덱스를 얻는다\n",
    "    if p == t[i]:\n",
    "        accuracy_cnt += 1\n",
    "\n",
    "print(\"Accuracy: \" + str(float(accuracy_cnt)/len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ##### 배치 처리\n",
    ">> * 배치: 하나로 묶은 입력 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(784,)\n",
      "(784, 50)\n",
      "(50, 100)\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "x, _ = get_data()\n",
    "\n",
    "network = init_network()\n",
    "\n",
    "W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "\n",
    "print(x.shape)\n",
    "print(x[0].shape)\n",
    "print(W1.shape)\n",
    "print(W2.shape)\n",
    "print(W3.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![elements](elements.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9352\n"
     ]
    }
   ],
   "source": [
    "# 배치 처리 구현\n",
    "x, t = get_data()\n",
    "network = init_network()\n",
    "\n",
    "batch_size = 100\n",
    "accuracy_cnt = 0\n",
    "\n",
    "for i in range(0, len(x), batch_size):\n",
    "    x_batch = x[i:i+batch_size]\n",
    "    y_batch = predict(network, x_batch)\n",
    "    p = np.argmax(y_batch, axis=1)\n",
    "    accuracy_cnt += np.sum(p==t[i:i+batch_size])\n",
    "\n",
    "print(\"Accuracy: \" + str(float(accuracy_cnt)/len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: 신경망 학습\n",
    "* 학습: 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것\n",
    "> ### **4.1** Learn from data\n",
    ">> ##### 데이터 주도 학습\n",
    ">> * 사람 중심의 접근이 아님 데이터 중심의 접근\n",
    ">> * 사람의 개입을 최소화, 기계가 패턴을 발견\n",
    ">> * 모든 문제를 같은 맥락에서 해결  \n",
    ">> (ex. 개를 인식하는 문제, 사람의 얼굴을 인식하는 문제에 관계없이 주어진 데이터를 온전히 학습하고, 문제의 패턴을 발견하려 시도)\n",
    ">> ##### traning set, test set\n",
    ">> * machine learning 문제는 traning data와 test data로 나누어서 학습 수행\n",
    ">> * 범용적으로 사용할 수 있는 모델 개발을 위해\n",
    ">> * 범용 능력을 제대로 평가하기 위해 data를 나눔  \n",
    ">> (범용 능력: 훈련 데이터에 포함되지 않은 데이터로도 문제를 올바르게 풀어내는 능력)\n",
    ">> * overfitting: 한 데이터셋에만 지나치게 최적화된 상태\n",
    "> ### **4.2** 손실 함수\n",
    "> * 손실 함수: 최적의 매개변수 값을 탐색하기 위한 지표, 신경망 성능의 '나쁨'을 나타내는 지표로 현재의 신경망의 훈련 데이터를 얼마나 잘 처리하지 못하느냐를 나타냄  \n",
    "> (일반적으로 평균 제곱 오차와 교차 엔트로피 오차 사용)\n",
    ">> ##### 평균 제곱 오차 (mean squared error, MSE)\n",
    ">> ![mse](mse.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE 구현\n",
    "def mean_squared_error(y, t):   # y, t: numpy array\n",
    "    return 0.5*np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09750000000000003\n"
     ]
    }
   ],
   "source": [
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "\n",
    "print(mean_squared_error(np.array(y), np.array(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ##### 교차 엔트로피 오차 (cross entropy error, CEE)\n",
    ">> ![cee](cee.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CEE 구현\n",
    "def cross_entropy_error(y, t):  # y, t: numpy array\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t*np.log(y+delta))   # np.log값이 0이 되어 -inf가 되지 않도록 delta를 더함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ##### 미니배치 학습\n",
    ">> ![cee_mean](cee_mean.png)\n",
    ">> * 미니배치: 신경망 학습에서 많은 양의 데이터에 대해 손실함수를 전부 구하는 것은 비현실적이며 비효율적, 따라서 데이터 일부를 추려 전체의 근사치로 활용함. 이때의 데이터의 일부\n",
    ">> * 미니배치 학습: 미니배치를 활용하여 학습하는 방법\n",
    ">> (ex. 60,000장의 훈련 데이터 중 100장을 무작위로 뽑아 활용하여 학습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# mnist 데이터 불러오기\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set 중 무작위로 10장 뽑기\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "\n",
    "x_batch = x_train[batch_mask]\n",
    "y_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ##### (배치용) CEE 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CEE, batch, one-hot label\n",
    "def cross_entropy_error(y,t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshpae(1, y.size)\n",
    "\n",
    "    batch_size = y.shape[0]\n",
    "    \n",
    "    return -np.sum(t*np.log(y+1e-7))/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CEE, batch, none one-hot label\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.dim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    \n",
    "    batch_size = y.shape[0]\n",
    "\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t]+1e-7))/batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ##### 왜 손실 함수를 설정하는가\n",
    ">> 왜 '정확도'라는 지표를 놔두고 '손실 함수'라는 우회적인 방법을 택하는가\n",
    ">> * 정확도를 지표로 하면 매개변수의 미분이 대부분의 지점에서 0이 되기 때문\n",
    ">> ![why_loss_function](why_loss_function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### **4.3** 수치 미분\n",
    "> * 수치 미분: 아주 작은 차분(임의의 두 점에서의 함수 값들의 차)으로 미분하는 것\n",
    "> * 해석적 미분, 수치 미분: 해적적 미분은 수학 시간에 배운 미분, 수치 미분은 근사치로 계산하는 방법\n",
    ">> ##### 미분\n",
    ">> ![derivative](derivative_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미분 구현 (나쁜 예)\n",
    "def numerical_diff(f, x):\n",
    "    h = 10e-50  # 반올림 오차(rounding error) 문제\n",
    "    return (f(x+h)-f(x))/h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![접선_근사](접선_근사.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미분 구현 (개선)\n",
    "def numerical_diff(f, x):\n",
    "    h = 1e-4\n",
    "    return (f(x+h)-f(x-h))/(2*h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ##### 수치 미분의 예\n",
    ">> ![diff_ex](diff_ex.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def function_1(x):\n",
    "    return 0.01*x**2 + 0.1*x\n",
    "\n",
    "x = np.arange(0.0, 20.0, 0.1)\n",
    "y = function_1(x)\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1999999999990898\n",
      "0.2999999999986347\n"
     ]
    }
   ],
   "source": [
    "def numerical_diff(f, x):\n",
    "    h = 1e-4\n",
    "    return (f(x+h)-f(x-h))/(2*h)\n",
    "\n",
    "# x=5, x=10일 때 함수의 미분 -> 함수의 기울기\n",
    "print(numerical_diff(function_1, 5))\n",
    "print(numerical_diff(function_1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![접선_수치미분](접선_수치미분.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ##### 편미분\n",
    ">> * 편미분: 변수가 여럿인 함수에 대한 미분\n",
    ">> ![partial_diff_ex](partial_diff_ex.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):  # x: numpy array\n",
    "    return x[0]**2 + x[1]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![partial_diff_ex_graph](partial_diff_ex_graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.00000000000378\n"
     ]
    }
   ],
   "source": [
    "# 편미분 연습 1\n",
    "def function_tmp1(x0):\n",
    "    return x0*x0 + 4.0**2.0\n",
    "\n",
    "print(numerical_diff(function_tmp1, 3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.999999999999119\n"
     ]
    }
   ],
   "source": [
    "# 편미분 연습 2\n",
    "def function_tmp2(x1):\n",
    "    return 3.0**2.0 + x1*x1\n",
    "\n",
    "print(numerical_diff(function_tmp2, 4.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### **4.4** 기울기\n",
    "> * 기울기: 모든 변수의 편미분을 벡터로 정리한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x):   # f: function, x: numpy array\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x) # x와 형상이 같고, 원소가 모두 0인 배열 생성\n",
    "\n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "\n",
    "        # f(x+h)\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "\n",
    "        # f(x-h)\n",
    "        x[idx] = tmp_val-h\n",
    "        fxh2 = f(x)\n",
    "\n",
    "        grad[idx] = (fxh1-fxh2)/(2*h)\n",
    "        x[idx] = tmp_val\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 8.]\n",
      "[0. 4.]\n",
      "[6. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(numerical_gradient(function_2, np.array([3.0, 4.0])))\n",
    "print(numerical_gradient(function_2, np.array([0.0, 2.0])))\n",
    "print(numerical_gradient(function_2, np.array([3.0, 0.0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gradient](gradient_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ##### 경사법 (경사 하강법)\n",
    ">> * 기울기가 가리키는 기울어진 방향이 꼭 최솟값을 가리키는 것은 아니나, 그 방향으로 가야 함수의 값을 줄일 수 있음  \n",
    ">> 따라서 최솟값 지점을 찾는 문제나 가능한 한 작은 값 지점을 찾는 문제에서는 기울기 정보를 단서로 나아갈 방향을 정해야 함\n",
    ">> * 경사법: 현 위치에서 기울어진 방향으로 일정 거리만큼 이동하고, 이동한 지점에서 기울기를 구하고, 그 기울어진 방향으로 나아가기를 반복, 함수의 값을 점차 줄이는 방법\n",
    ">> ![gradient_descent](gradient_descent.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent\n",
    "def gradient_descent(f, init_x, lr=0.01, step_num=100): # f: 최적화하려는 함수, init_x: 초기값, lr: learning rate, step_num: 반복 횟수\n",
    "    x = init_x\n",
    "\n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr*grad\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.11110793e-10  8.14814391e-10]\n"
     ]
    }
   ],
   "source": [
    "# practice gradient descent\n",
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "init_x = np.array([-3.0,4.0])\n",
    "print(gradient_descent(function_2, init_x=init_x, lr=0.1, step_num=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gradient_descent_graph](gradient_descent_graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.58983747e+13 -1.29524862e+12]\n",
      "[-2.99999994  3.99999992]\n"
     ]
    }
   ],
   "source": [
    "# 학습률이 너무 클 때 -> 발산\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "print(gradient_descent(function_2, init_x, lr=10.0, step_num=100))\n",
    "\n",
    "# 학습률이 너무 작을 때 -> 갱신되지 않은 채 끝남\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "print(gradient_descent(function_2, init_x=init_x, lr=1e-10, step_num=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ##### 신경망에서의 기울기\n",
    ">> ![gradient_neural_network](gradient_neural_network_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망에서의 기울기\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from common.functions import softmax, cross_entropy_error\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2,3)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "    \n",
    "    def loss(self, x, t):   # x: 입력 데이터, t: 정답 레이블\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.3180683   0.06962764  1.37375347]\n",
      " [-0.10906724  0.28794975  0.52204191]]\n",
      "[0.09268046 0.30093136 1.2940898 ]\n",
      "2\n",
      "0.5135267824858393\n"
     ]
    }
   ],
   "source": [
    "net = simpleNet()\n",
    "print(net.W)\n",
    "\n",
    "x = np.array([0.6, 0.9])\n",
    "p = net.predict(x)\n",
    "print(p)\n",
    "print(np.argmax(p))\n",
    "\n",
    "t = np.array([0, 0, 1])\n",
    "print(net.loss(x, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10798509  0.13298603 -0.24097112]\n",
      " [ 0.16197764  0.19947905 -0.36145669]]\n"
     ]
    }
   ],
   "source": [
    "def f(W):\n",
    "    return net.loss(x, t)\n",
    "\n",
    "dW = numerical_gradient(f, net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### **4.5** 학습 알고리즘 구현하기\n",
    ">\n",
    "> 신경망 학습의 순서 (확률적 경사 하강법 stochastic gradient descent, SGD)\n",
    "> * 1단계 - 미니배치  \n",
    "> 훈련 데이터 중 일부를 무작위로 가져옴\n",
    ">\n",
    "> * 2단계 - 기울기 산출  \n",
    "> 미니배치의 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구함. 기울기는 손실 함수의 값을 가장 작게 하는 방향을 제시\n",
    ">\n",
    "> * 3단계 - 매개변수 갱신  \n",
    "> 가중치 매개변수를 기울기 방향으로 아주 조금 갱신\n",
    ">\n",
    "> * 4단계 - 반복  \n",
    ">  1~3단계 반복\n",
    ">\n",
    ">> ##### 2층 신경망 클래스 구현하기\n",
    ">> ![2layer_variable_methods](2layer_variable_methods.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std*np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std*np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "\n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "\n",
    "        accuracy = np.sum(y==t)/float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x,t)\n",
    "\n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        grads = {}\n",
    "\n",
    "        batch_num = x.shape[0]\n",
    "\n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "\n",
    "        dy = (y - t) / batch_num\n",
    "        grads['W2'] = np.dot(z1.T, dy)\n",
    "        grads['b2'] = np.sum(dy, axis=0)\n",
    "        \n",
    "        da1 = np.dot(dy, W2.T)\n",
    "        dz1 = sigmoid_grad(a1) * da1\n",
    "        grads['W1'] = np.dot(x.T, dz1)\n",
    "        grads['b1'] = np.sum(dz1, axis=0)\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100,)\n",
      "(100, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)\n",
    "\n",
    "print(net.params['W1'].shape)\n",
    "print(net.params['b1'].shape)\n",
    "print(net.params['W2'].shape)\n",
    "print(net.params['b2'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(784, 100)\n",
      "(100, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(100, 784)    # 더미 입력 데이터 (100장)\n",
    "y = net.predict(x)\n",
    "t = np.random.rand(100, 10)    # 더미 정답 레이블 (100장)\n",
    "\n",
    "grads = net.numerical_gradient(x, t)\n",
    "print(grads['W1'].shape)\n",
    "print(grads['W1'].shape)\n",
    "print(grads['W2'].shape)\n",
    "print(grads['b2'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ##### 미니배치 학습 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list = []\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    # 기울치 계산\n",
    "    # grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch) # 성능 개선\n",
    "\n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mini_batch](mini_batch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ##### 시험 데이터로 평가하기\n",
    ">> * epoch: 단위, 1epoch = 학습에서 훈련 데이터를 모두 소진했을 때 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc, test acc: 0.10218333333333333, 0.101\n",
      "train acc, test acc: 0.7902833333333333, 0.7917\n",
      "train acc, test acc: 0.8757, 0.8796\n",
      "train acc, test acc: 0.89955, 0.9021\n",
      "train acc, test acc: 0.9091166666666667, 0.9121\n",
      "train acc, test acc: 0.9153833333333333, 0.9159\n",
      "train acc, test acc: 0.92035, 0.9213\n",
      "train acc, test acc: 0.9239333333333334, 0.9232\n",
      "train acc, test acc: 0.9286166666666666, 0.9295\n",
      "train acc, test acc: 0.9321666666666667, 0.9317\n",
      "train acc, test acc: 0.93385, 0.9331\n",
      "train acc, test acc: 0.9375166666666667, 0.936\n",
      "train acc, test acc: 0.9395666666666667, 0.9384\n",
      "train acc, test acc: 0.9419833333333333, 0.9389\n",
      "train acc, test acc: 0.9447833333333333, 0.9421\n",
      "train acc, test acc: 0.9461333333333334, 0.9437\n",
      "train acc, test acc: 0.9478, 0.9451\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size/batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    # 기울치 계산\n",
    "    # grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch) # 성능 개선\n",
    "\n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "\n",
    "    # 1epoch 당 정확도 계산\n",
    "    if i%iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc: \"+str(train_acc)+\", \"+str(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![accuracy_graph](accuracy_graph_1.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
